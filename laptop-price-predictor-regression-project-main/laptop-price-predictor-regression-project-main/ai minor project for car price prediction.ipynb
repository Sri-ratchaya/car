{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5c2a82a-79e7-426f-bac7-80f1d1715116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dac4ceb5-a8d7-43ff-b110-c925b8977118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Year</th>\n",
       "      <th>Kilometers_Driven</th>\n",
       "      <th>Fuel_Type</th>\n",
       "      <th>Transmission</th>\n",
       "      <th>Owner_Type</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>Engine</th>\n",
       "      <th>Power</th>\n",
       "      <th>Seats</th>\n",
       "      <th>New_Price</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Maruti Wagon R LXI CNG</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2010</td>\n",
       "      <td>72000</td>\n",
       "      <td>CNG</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First</td>\n",
       "      <td>26.6 km/kg</td>\n",
       "      <td>998 CC</td>\n",
       "      <td>58.16 bhp</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Hyundai Creta 1.6 CRDi SX Option</td>\n",
       "      <td>Pune</td>\n",
       "      <td>2015</td>\n",
       "      <td>41000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First</td>\n",
       "      <td>19.67 kmpl</td>\n",
       "      <td>1582 CC</td>\n",
       "      <td>126.2 bhp</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Honda Jazz V</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>2011</td>\n",
       "      <td>46000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First</td>\n",
       "      <td>18.2 kmpl</td>\n",
       "      <td>1199 CC</td>\n",
       "      <td>88.7 bhp</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.61 Lakh</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Maruti Ertiga VDI</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>2012</td>\n",
       "      <td>87000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First</td>\n",
       "      <td>20.77 kmpl</td>\n",
       "      <td>1248 CC</td>\n",
       "      <td>88.76 bhp</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Audi A4 New 2.0 TDI Multitronic</td>\n",
       "      <td>Coimbatore</td>\n",
       "      <td>2013</td>\n",
       "      <td>40670</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Second</td>\n",
       "      <td>15.2 kmpl</td>\n",
       "      <td>1968 CC</td>\n",
       "      <td>140.8 bhp</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                              Name    Location  Year  \\\n",
       "0           0            Maruti Wagon R LXI CNG      Mumbai  2010   \n",
       "1           1  Hyundai Creta 1.6 CRDi SX Option        Pune  2015   \n",
       "2           2                      Honda Jazz V     Chennai  2011   \n",
       "3           3                 Maruti Ertiga VDI     Chennai  2012   \n",
       "4           4   Audi A4 New 2.0 TDI Multitronic  Coimbatore  2013   \n",
       "\n",
       "   Kilometers_Driven Fuel_Type Transmission Owner_Type     Mileage   Engine  \\\n",
       "0              72000       CNG       Manual      First  26.6 km/kg   998 CC   \n",
       "1              41000    Diesel       Manual      First  19.67 kmpl  1582 CC   \n",
       "2              46000    Petrol       Manual      First   18.2 kmpl  1199 CC   \n",
       "3              87000    Diesel       Manual      First  20.77 kmpl  1248 CC   \n",
       "4              40670    Diesel    Automatic     Second   15.2 kmpl  1968 CC   \n",
       "\n",
       "       Power  Seats  New_Price  Price  \n",
       "0  58.16 bhp    5.0        NaN   1.75  \n",
       "1  126.2 bhp    5.0        NaN  12.50  \n",
       "2   88.7 bhp    5.0  8.61 Lakh   4.50  \n",
       "3  88.76 bhp    7.0        NaN   6.00  \n",
       "4  140.8 bhp    5.0        NaN  17.74  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Load the 2024 dataset\n",
    "dataset = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "# Initial exploration\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09f6f091-6010-4aa0-b1cf-351749bc6a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Splitting into train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.iloc[:, :-1], \n",
    "                                                    dataset.iloc[:, -1], \n",
    "                                                    test_size = 0.3, \n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d9dafb6-b4ea-42ec-a8e3-0e24231ad685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing: Cleaning steps (dropping columns, filling missing values, converting types) as done previously\n",
    "X_train = X_train.iloc[:, 1:]  # Removing 'Unnamed: 0' index column\n",
    "X_test = X_test.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "315de35f-5c73-4523-9137-847e0eb7645a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract manufacturer from 'Name' column\n",
    "make_train = X_train[\"Name\"].str.split(\" \", expand = True)\n",
    "make_test = X_test[\"Name\"].str.split(\" \", expand = True)\n",
    "X_train[\"Manufacturer\"] = make_train[0]\n",
    "X_test[\"Manufacturer\"] = make_test[0]\n",
    "X_train.drop(\"Name\", axis = 1, inplace = True)\n",
    "X_test.drop(\"Name\", axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13e34376-4493-4b64-a4eb-fcf2105a1596",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Removing the 'Location' column as it is irrelevant\n",
    "X_train.drop(\"Location\", axis = 1, inplace = True)\n",
    "X_test.drop(\"Location\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1e3999f-8e96-4cbf-a544-f7a24a9c9876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling 'Year' column to represent the car's age\n",
    "curr_time = datetime.datetime.now()\n",
    "X_train['Year'] = X_train['Year'].apply(lambda x : curr_time.year - x)\n",
    "X_test['Year'] = X_test['Year'].apply(lambda x : curr_time.year - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9e39e9d-e4ff-411f-9453-cd997cddca2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Handle categorical columns (Fuel_Type, Transmission, Owner_Type)\n",
    "X_train = pd.get_dummies(X_train, columns=[\"Manufacturer\", \"Fuel_Type\", \"Transmission\", \"Owner_Type\"], drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, columns=[\"Manufacturer\", \"Fuel_Type\", \"Transmission\", \"Owner_Type\"], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bf0809c-60b6-42c0-821a-9a46c20b7d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing columns between train and test set\n",
    "missing_cols = set(X_train.columns) - set(X_test.columns)\n",
    "for col in missing_cols:\n",
    "    X_test[col] = 0\n",
    "X_test = X_test[X_train.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c1356bc-5bb8-4a05-9a3d-d7070e29ea78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                              Name    Location  Year  \\\n",
      "0           0            Maruti Wagon R LXI CNG      Mumbai  2010   \n",
      "1           1  Hyundai Creta 1.6 CRDi SX Option        Pune  2015   \n",
      "2           2                      Honda Jazz V     Chennai  2011   \n",
      "3           3                 Maruti Ertiga VDI     Chennai  2012   \n",
      "4           4   Audi A4 New 2.0 TDI Multitronic  Coimbatore  2013   \n",
      "\n",
      "   Kilometers_Driven Fuel_Type Transmission Owner_Type     Mileage   Engine  \\\n",
      "0              72000       CNG       Manual      First  26.6 km/kg   998 CC   \n",
      "1              41000    Diesel       Manual      First  19.67 kmpl  1582 CC   \n",
      "2              46000    Petrol       Manual      First   18.2 kmpl  1199 CC   \n",
      "3              87000    Diesel       Manual      First  20.77 kmpl  1248 CC   \n",
      "4              40670    Diesel    Automatic     Second   15.2 kmpl  1968 CC   \n",
      "\n",
      "       Power  Seats  New_Price  Price  \n",
      "0  58.16 bhp    5.0        NaN   1.75  \n",
      "1  126.2 bhp    5.0        NaN  12.50  \n",
      "2   88.7 bhp    5.0  8.61 Lakh   4.50  \n",
      "3  88.76 bhp    7.0        NaN   6.00  \n",
      "4  140.8 bhp    5.0        NaN  17.74  \n",
      "Data preprocessing completed successfully!\n",
      "Training data shape: (4813, 2948)\n",
      "Testing data shape: (1204, 2948)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Inspect the dataset for anomalies\n",
    "print(df.head())  # Ensure columns are correctly aligned and data types are valid\n",
    "\n",
    "# Define a function to clean and extract Mileage values\n",
    "def clean_Mileage(value):\n",
    "    \"\"\"\n",
    "    Cleans and extracts numeric Mileage values from strings.\n",
    "    Handles cases where Mileage is specified in 'kmpl' or 'km/kg'.\n",
    "    Returns None for invalid or non-numeric entries.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if isinstance(value, str):  # Check if value is a string\n",
    "            if 'kmpl' in value:\n",
    "                return float(value.replace(' kmpl', ''))\n",
    "            elif 'km/kg' in value:\n",
    "                return float(value.replace(' km/kg', ''))\n",
    "        return None  # Return None for non-matching or invalid values\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing value '{value}': {e}\")\n",
    "        return None\n",
    "\n",
    "# Apply the cleaning function to the Mileage column\n",
    "if 'Mileage' in df.columns:\n",
    "    df['Mileage'] = df['Mileage'].apply(clean_Mileage)\n",
    "else:\n",
    "    raise ValueError(\"Mileage column not found in the dataset.\")\n",
    "\n",
    "# Drop rows with invalid or missing Mileage values\n",
    "df = df.dropna(subset=['Mileage'])\n",
    "\n",
    "# Ensure the target column is present\n",
    "target_column = 'Price'  # Replace with your actual target column name\n",
    "if target_column not in df.columns:\n",
    "    raise ValueError(f\"Target column '{target_column}' not found in the dataset. Check your dataset.\")\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(target_column, axis=1)  # Drop target column to isolate features\n",
    "y = df[target_column]  # Target variable\n",
    "\n",
    "# Handle categorical features (convert to numeric using one-hot encoding)\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "if not categorical_columns.empty:\n",
    "    X = pd.get_dummies(X, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the feature data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Confirm successful processing\n",
    "print(\"Data preprocessing completed successfully!\")\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f241c266-d02d-4827-b6ad-fcaf022f9257",
   "metadata": {},
   "source": [
    "# training model and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "456727a0-72bc-484c-8863-7db3b7a64371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression R2 score: -2.2284504132231393\n",
      "Random Forest R2 score: -8.0748125\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Impute missing values in features\n",
    "imputer = SimpleImputer(strategy='mean')  # Use mean to replace NaN values\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# Linear Regression Model\n",
    "linearRegression = LinearRegression()\n",
    "linearRegression.fit(X_train, y_train)\n",
    "y_pred_lr = linearRegression.predict(X_test)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "print(f\"Linear Regression R2 score: {r2_lr}\")\n",
    "\n",
    "# Random Forest Regressor Model\n",
    "rf = RandomForestRegressor(n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest R2 score: {r2_rf}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bea9065-17f4-4f68-8c6b-7bd0a73d9a51",
   "metadata": {},
   "source": [
    "# model accurracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68e49074-f53b-4521-b6dc-479c5cf0889d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Brand     Model  Year  Mileage Fuel_Type Transmission  Price\n",
      "0  Toyota   Corolla  2025     15.5    Petrol    Automatic  25000\n",
      "1   Honda     Civic  2025     12.0    Diesel       Manual  28000\n",
      "2    Ford     Focus  2025     13.0    Petrol       Manual  23000\n",
      "3     BMW  3 Series  2025     10.5    Diesel    Automatic  40000\n",
      "4    Audi        A4  2025     11.5    Petrol    Automatic  35000\n",
      "   Year  Mileage  Price  Fuel_Type_Petrol  Transmission_Manual\n",
      "0     0     15.5  25000              True                False\n",
      "1     0     12.0  28000             False                 True\n",
      "2     0     13.0  23000              True                 True\n",
      "3     0     10.5  40000             False                False\n",
      "4     0     11.5  35000              True                False\n",
      "Year                     int64\n",
      "Mileage                float64\n",
      "Fuel_Type_Petrol          bool\n",
      "Transmission_Manual       bool\n",
      "dtype: object\n",
      "Model accuracy on test set: -9.803025\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv(\"car predict 2025 assum.csv\")  # Replace with the correct path\n",
    "\n",
    "# Check for non-numeric data and inspect columns\n",
    "print(dataset.head())  # View the first few rows to check the data\n",
    "\n",
    "# Remove any non-numeric columns that aren't useful for prediction (e.g., 'Brand', 'Model')\n",
    "dataset.drop(['Brand', 'Model'], axis=1, inplace=True)  # Drop 'Brand' and 'Model' columns\n",
    "\n",
    "# Apply necessary preprocessing steps\n",
    "dataset['Year'] = dataset['Year'].apply(lambda x: 2025 - x)  # Adjusting the year for prediction\n",
    "\n",
    "# Handle Fuel_Type by encoding it (it’s a categorical feature)\n",
    "make_train = dataset[\"Fuel_Type\"].str.split(\" \", expand=True)\n",
    "dataset[\"Fuel_Type\"] = make_train[0]  # Simplify or handle accordingly\n",
    "\n",
    "# Apply one-hot encoding for categorical columns like 'Fuel_Type' and 'Transmission'\n",
    "dataset = pd.get_dummies(dataset, columns=[\"Fuel_Type\", \"Transmission\"], drop_first=True)\n",
    "\n",
    "# Check again for non-numeric columns after transformation\n",
    "print(dataset.head())  # View the dataset after encoding\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = dataset.drop(\"Price\", axis=1)  # All columns except 'Price'\n",
    "y = dataset['Price']  # The target variable is 'Price'\n",
    "\n",
    "# Ensure all columns are numeric\n",
    "print(X.dtypes)  # Ensure no non-numeric columns are present\n",
    "\n",
    "# Convert any remaining non-numeric columns if they exist (e.g., 'Fuel_Type_Petrol' or 'Transmission_Manual')\n",
    "# This is usually handled by pd.get_dummies(), but if there are any unexpected string columns, handle them\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the RandomForest model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained Random Forest model\n",
    "joblib.dump(rf, 'rf_model.pkl')\n",
    "\n",
    "# Save the StandardScaler used for scaling (if necessary)\n",
    "standardScaler = StandardScaler()\n",
    "X_train_scaled = standardScaler.fit_transform(X_train)\n",
    "joblib.dump(standardScaler, 'scaler.pkl')\n",
    "\n",
    "# Evaluate the model (optional)\n",
    "print(\"Model accuracy on test set:\", rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcad7f3-c21c-4e80-acfc-555aac9b1685",
   "metadata": {},
   "source": [
    "# convert to numeric value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6a5848eb-5b57-4bc2-becd-daaac6c433c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.68556048]\n",
      " [ 1.29098365]\n",
      " [-0.78316759]\n",
      " ...\n",
      " [-0.83197115]\n",
      " [-0.77503367]\n",
      " [ 1.96145159]]\n",
      "      Unnamed: 0                              Name    Location  Year  \\\n",
      "0              0            Maruti Wagon R LXI CNG      Mumbai  2010   \n",
      "1              1  Hyundai Creta 1.6 CRDi SX Option        Pune  2015   \n",
      "2              2                      Honda Jazz V     Chennai  2011   \n",
      "3              3                 Maruti Ertiga VDI     Chennai  2012   \n",
      "4              4   Audi A4 New 2.0 TDI Multitronic  Coimbatore  2013   \n",
      "...          ...                               ...         ...   ...   \n",
      "6014        6014                  Maruti Swift VDI       Delhi  2014   \n",
      "6015        6015          Hyundai Xcent 1.1 CRDi S      Jaipur  2015   \n",
      "6016        6016             Mahindra Xylo D4 BSIV      Jaipur  2012   \n",
      "6017        6017                Maruti Wagon R VXI     Kolkata  2013   \n",
      "6018        6018             Chevrolet Beat Diesel   Hyderabad  2011   \n",
      "\n",
      "      Kilometers_Driven Fuel_Type Transmission Owner_Type  Mileage   Engine  \\\n",
      "0                 72000       CNG       Manual      First    266.0   998 CC   \n",
      "1                 41000    Diesel       Manual      First   1967.0  1582 CC   \n",
      "2                 46000    Petrol       Manual      First    182.0  1199 CC   \n",
      "3                 87000    Diesel       Manual      First   2077.0  1248 CC   \n",
      "4                 40670    Diesel    Automatic     Second    152.0  1968 CC   \n",
      "...                 ...       ...          ...        ...      ...      ...   \n",
      "6014              27365    Diesel       Manual      First    284.0  1248 CC   \n",
      "6015             100000    Diesel       Manual      First    244.0  1120 CC   \n",
      "6016              55000    Diesel       Manual     Second    140.0  2498 CC   \n",
      "6017              46000    Petrol       Manual      First    189.0   998 CC   \n",
      "6018              47000    Diesel       Manual      First   2544.0   936 CC   \n",
      "\n",
      "          Power  Seats  New_Price  Price  \n",
      "0     58.16 bhp    5.0        NaN   1.75  \n",
      "1     126.2 bhp    5.0        NaN  12.50  \n",
      "2      88.7 bhp    5.0  8.61 Lakh   4.50  \n",
      "3     88.76 bhp    7.0        NaN   6.00  \n",
      "4     140.8 bhp    5.0        NaN  17.74  \n",
      "...         ...    ...        ...    ...  \n",
      "6014     74 bhp    5.0  7.88 Lakh   4.75  \n",
      "6015     71 bhp    5.0        NaN   4.00  \n",
      "6016    112 bhp    8.0        NaN   2.90  \n",
      "6017   67.1 bhp    5.0        NaN   2.65  \n",
      "6018   57.6 bhp    5.0        NaN   2.50  \n",
      "\n",
      "[6019 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset from CSV file\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Clean the 'Mileage' column: remove non-numeric characters (e.g., ' km/kg')\n",
    "df['Mileage'] = df['Mileage'].replace(r'\\D', '', regex=True).astype(float)\n",
    "# Now you can apply StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the 'Mileage' data\n",
    "scaler.fit(df[['Mileage']])\n",
    "\n",
    "# If you want to scale the dataset for prediction, for example, for X_2024\n",
    "X_2024 = df[['Mileage']]  # Replace with your actual dataset columns\n",
    "X_2024_scaled = scaler.transform(X_2024)\n",
    "\n",
    "# Print the scaled data\n",
    "print(X_2024_scaled)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "396e37c4-69bf-41a8-b183-7e73af15d723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_features.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Example: Train a Random Forest model\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)  # X_train, y_train are your training features and target labels\n",
    "\n",
    "# Now, save the feature names\n",
    "model_features = rf.feature_names_in_\n",
    "joblib.dump(model_features, 'model_features.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935ef0c7-72cd-4711-82fb-79a045da829a",
   "metadata": {},
   "source": [
    "# predict f0r 2025 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "15d5d796-d5a2-40db-b00e-31546f9ec8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in dataset_2024: Index(['Unnamed: 0', 'Name', 'Location', 'Year', 'Kilometers_Driven',\n",
      "       'Fuel_Type', 'Transmission', 'Owner_Type', 'Mileage', 'Engine', 'Power',\n",
      "       'Seats', 'New_Price', 'Price'],\n",
      "      dtype='object')\n",
      "Columns in dataset_2025: Index(['Brand', 'Model', 'Year', 'Mileage', 'Fuel_Type', 'Transmission',\n",
      "       'Price'],\n",
      "      dtype='object')\n",
      "Price Comparison for 2024 and 2025:\n",
      "   Year  Predicted Price\n",
      "0  2024          42560.0\n",
      "1  2024          42560.0\n",
      "2  2024          36070.0\n",
      "3  2024          42560.0\n",
      "4  2024          42640.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the trained model and scaler\n",
    "rf = joblib.load('rf_model.pkl')  # Load the Random Forest model\n",
    "standardScaler = joblib.load('scaler.pkl')  # Load the StandardScaler if used\n",
    "\n",
    "# Load the dataset for 2024 and 2025 (assuming you have datasets containing 2024 and 2025 data)\n",
    "dataset_2024 = pd.read_csv(\"dataset.csv\")  # Replace with actual path to the 2024 dataset\n",
    "dataset_2025 = pd.read_csv(\"car predict 2025 assum.csv\")  # Corrected filename\n",
    "\n",
    "# Print column names to inspect the dataset\n",
    "print(\"Columns in dataset_2024:\", dataset_2024.columns)\n",
    "print(\"Columns in dataset_2025:\", dataset_2025.columns)\n",
    "\n",
    "# Drop non-numeric columns like 'Brand' and 'Model' if they exist in both datasets\n",
    "columns_to_drop = ['Brand', 'Model']\n",
    "for col in columns_to_drop:\n",
    "    if col in dataset_2024.columns:\n",
    "        dataset_2024 = dataset_2024.drop(col, axis=1)  # Drop column and reassign to avoid chained assignment\n",
    "    if col in dataset_2025.columns:\n",
    "        dataset_2025 = dataset_2025.drop(col, axis=1)  # Drop column and reassign to avoid chained assignment\n",
    "\n",
    "# Clean the 'Fuel_Efficiency' column (or any other similar column)\n",
    "for col in ['Fuel_Efficiency']:  # Replace with the actual column name causing the issue\n",
    "    if col in dataset_2024.columns:\n",
    "        # Convert to string and clean, handling any non-numeric characters\n",
    "        dataset_2024[col] = dataset_2024[col].astype(str).str.replace(r'[^0-9.]', '', regex=True)\n",
    "        dataset_2024[col] = pd.to_numeric(dataset_2024[col], errors='coerce')\n",
    "        dataset_2024[col] = dataset_2024[col].fillna(dataset_2024[col].mean())  # Fill NaNs with the mean value\n",
    "\n",
    "    if col in dataset_2025.columns:\n",
    "        dataset_2025[col] = dataset_2025[col].astype(str).str.replace(r'[^0-9.]', '', regex=True)\n",
    "        dataset_2025[col] = pd.to_numeric(dataset_2025[col], errors='coerce')\n",
    "        dataset_2025[col] = dataset_2025[col].fillna(dataset_2025[col].mean())  # Fill NaNs with the mean value\n",
    "\n",
    "# Clean the 'Mileage' column in both datasets\n",
    "for col in ['Mileage']:\n",
    "    if col in dataset_2024.columns:\n",
    "        dataset_2024[col] = dataset_2024[col].astype(str).str.replace(r'[^0-9.]', '', regex=True)\n",
    "        dataset_2024[col] = pd.to_numeric(dataset_2024[col], errors='coerce')\n",
    "        dataset_2024[col] = dataset_2024[col].fillna(dataset_2024[col].mean())  # Fill NaNs with the mean value\n",
    "    if col in dataset_2025.columns:\n",
    "        dataset_2025[col] = dataset_2025[col].astype(str).str.replace(r'[^0-9.]', '', regex=True)\n",
    "        dataset_2025[col] = pd.to_numeric(dataset_2025[col], errors='coerce')\n",
    "        dataset_2025[col] = dataset_2025[col].fillna(dataset_2025[col].mean())  # Fill NaNs with the mean value\n",
    "\n",
    "# Adjust the 'Year' column for prediction\n",
    "dataset_2024['Year'] = dataset_2024['Year'].apply(lambda x: 2025 - x)  # Adjusting the year for prediction\n",
    "dataset_2025['Year'] = dataset_2025['Year'].apply(lambda x: 2025 - x)  # Adjusting the year for prediction\n",
    "\n",
    "# Process 'Fuel_Type' column (split if needed)\n",
    "for dataset in [dataset_2024, dataset_2025]:\n",
    "    make_train = dataset[\"Fuel_Type\"].str.split(\" \", expand=True)\n",
    "    dataset[\"Fuel_Type\"] = make_train[0]\n",
    "\n",
    "# Apply one-hot encoding for 'Fuel_Type' and 'Transmission' for both 2024 and 2025\n",
    "dataset_2024 = pd.get_dummies(dataset_2024, columns=[\"Fuel_Type\", \"Transmission\"], drop_first=True)\n",
    "dataset_2025 = pd.get_dummies(dataset_2025, columns=[\"Fuel_Type\", \"Transmission\"], drop_first=True)\n",
    "\n",
    "# Ensure the columns are in the same order for both datasets\n",
    "model_features = joblib.load('model_features.pkl')  # Load the saved feature names\n",
    "\n",
    "# Align the datasets with the same feature columns\n",
    "dataset_2024 = dataset_2024[model_features]\n",
    "dataset_2025 = dataset_2025[model_features]\n",
    "\n",
    "# Define features (X) for 2024 and 2025 data (without the target column 'Price')\n",
    "X_2024 = dataset_2024\n",
    "X_2025 = dataset_2025\n",
    "\n",
    "# Scale the features using the pre-fitted scaler\n",
    "X_2024_scaled = standardScaler.transform(X_2024)\n",
    "X_2025_scaled = standardScaler.transform(X_2025)\n",
    "\n",
    "# Ensure that X_2024 and X_2025 have feature names\n",
    "X_2024_scaled = pd.DataFrame(X_2024_scaled, columns=X_2024.columns)\n",
    "X_2025_scaled = pd.DataFrame(X_2025_scaled, columns=X_2025.columns)\n",
    "\n",
    "# Predict the prices for the 2024 and 2025 data\n",
    "predicted_prices_2024 = rf.predict(X_2024_scaled)\n",
    "predicted_prices_2025 = rf.predict(X_2025_scaled)\n",
    "\n",
    "# Compare predicted prices for both years\n",
    "comparison_2024 = pd.DataFrame({\n",
    "    'Year': [2024] * len(predicted_prices_2024),\n",
    "    'Predicted Price': predicted_prices_2024\n",
    "})\n",
    "\n",
    "comparison_2025 = pd.DataFrame({\n",
    "    'Year': [2025] * len(predicted_prices_2025),\n",
    "    'Predicted Price': predicted_prices_2025\n",
    "})\n",
    "\n",
    "# Combine both years into one DataFrame for comparison\n",
    "comparison = pd.concat([comparison_2024, comparison_2025])\n",
    "\n",
    "# Save the comparison results to a CSV file\n",
    "comparison.to_csv('price_comparison_2024_2025.csv', index=False)\n",
    "\n",
    "# Display the comparison for both years\n",
    "print(\"Price Comparison for 2024 and 2025:\")\n",
    "print(comparison.head())  # Display a few rows of the comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1dd4f9-8434-4389-a777-4d271ad389a9",
   "metadata": {},
   "source": [
    "# comparsion in price difference of 2024 and 2025 year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b0196f99-930f-4749-a457-579ca82a62c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted Price_2024  Predicted Price_2025  Price Difference  \\\n",
      "0               42560.0               36730.0           -5830.0   \n",
      "1               42560.0               42560.0               0.0   \n",
      "2               36070.0               36070.0               0.0   \n",
      "3               42560.0               42640.0              80.0   \n",
      "4               42640.0               36730.0           -5910.0   \n",
      "5               42560.0               42640.0              80.0   \n",
      "6               42560.0               36070.0           -6490.0   \n",
      "7               42640.0               36730.0           -5910.0   \n",
      "8               42560.0               42560.0               0.0   \n",
      "9               42560.0               36730.0           -5830.0   \n",
      "\n",
      "   Percentage Rise  \n",
      "0       -13.698308  \n",
      "1         0.000000  \n",
      "2         0.000000  \n",
      "3         0.187970  \n",
      "4       -13.860225  \n",
      "5         0.187970  \n",
      "6       -15.249060  \n",
      "7       -13.860225  \n",
      "8         0.000000  \n",
      "9       -13.698308  \n"
     ]
    }
   ],
   "source": [
    "# Merge the two DataFrames using their index\n",
    "merged_comparison = pd.merge(comparison_2024, comparison_2025, left_index=True, right_index=True, suffixes=('_2024', '_2025'))\n",
    "\n",
    "# Calculate the difference in prices between 2025 and 2024\n",
    "merged_comparison['Price Difference'] = merged_comparison['Predicted Price_2025'] - merged_comparison['Predicted Price_2024']\n",
    "\n",
    "# Calculate the percentage rise in 2025 car price\n",
    "merged_comparison['Percentage Rise'] = ((merged_comparison['Predicted Price_2025'] - merged_comparison['Predicted Price_2024']) / merged_comparison['Predicted Price_2024']) * 100\n",
    "\n",
    "# Display the DataFrame with Percentage Rise\n",
    "print(merged_comparison[['Predicted Price_2024', 'Predicted Price_2025', 'Price Difference', 'Percentage Rise']])\n",
    "comparison.to_csv('difference in 2024 and 2025.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ad4754-9f1b-4be3-ba44-35ed283bdb95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe9a66c-8035-4abc-9c0b-30567081d5d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf837e4-30f5-446a-b923-b41adecc6bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927de809-8c33-470c-9f74-4ba5f3c17471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e76350f-813a-4fc0-ac06-f5ca321de243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42cf030-dddc-48f6-8701-67261521fa69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6271b590-bb70-4a80-aa19-27bc1e248f86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b89b41f-f527-4b18-810d-7f02ad2489cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4aa9eb-9185-4bf8-aac7-d323dc24184a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
